{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d239412",
   "metadata": {},
   "source": [
    "# YOLOv7 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb9e79",
   "metadata": {},
   "source": [
    "### importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c011c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71b678",
   "metadata": {},
   "source": [
    "### Downloading yolov7 model with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cda97f",
   "metadata": {},
   "source": [
    "### installing all required libraries for yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov7\n",
    "!pip install -r requirements.txt\n",
    "!pip uninstall wandb -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19480732",
   "metadata": {},
   "source": [
    "### downloading the tiny model to train on custom dataset\n",
    "#### you can use the regular model (https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt) but it will be larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9807bf",
   "metadata": {},
   "source": [
    "### creating custom config for custom data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e78871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile config/pothole.yaml\n",
    "train: ../dataset/images/train \n",
    "val: ../dataset/images/valid\n",
    "test: ../dataset/images/test\n",
    "\n",
    "# Classes\n",
    "nc: 1  # number of classes\n",
    "names: ['pothole']  # class names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2312de",
   "metadata": {},
   "source": [
    "### changing class number because we used only 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = open(\"yolov7/cfg/training/yolov7-tiny.yaml\",\"r\").readlines()\n",
    "old[1] = \"nc: 1  # number of classes\\n\"\n",
    "new = open(\"yolov7/cfg/training/yolov7-tiny.yaml\",\"w\")\n",
    "for line in old:\n",
    "    new.writelines(line)\n",
    "new.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45af6a",
   "metadata": {},
   "source": [
    "### Model Training & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --epochs 100 --workers 4 --device 0 --batch-size 4 --data data/pothole.yaml --img 640 640 --cfg config/pothole.yaml --weights 'yolov7-tiny.pt' --name pothole --hyp data/hyp.scratch.tiny.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2fdb3",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366dc86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd01fbf",
   "metadata": {},
   "source": [
    "# CNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88321736",
   "metadata": {},
   "source": [
    "### importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ee05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "   \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import PIL\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da942566",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_dir = \"DataSet2/Train/\"\n",
    "Validate_data_dir = \"DataSet2/Valid/\"\n",
    "Train_data_dir = pathlib.Path(Train_data_dir)\n",
    "Validate_data_dir = pathlib.Path(Validate_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d851a83",
   "metadata": {},
   "source": [
    "### Basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  Train_data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  Validate_data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2199f72",
   "metadata": {},
   "source": [
    "### Preprocessing data to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4540a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041357be",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f862f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea557bea",
   "metadata": {},
   "source": [
    "### Model Training & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c75095",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "model.save('CNN_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
